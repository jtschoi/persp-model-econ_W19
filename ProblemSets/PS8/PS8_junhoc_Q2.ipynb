{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACS30150 PS8 (Question 2)\n",
    "### Dr. Richard Evans\n",
    "### Submitted by Junho Choi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us import the necessary functions and packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from sklearn.ensemble import RandomForestRegressor as RanForReg\n",
    "from sklearn.ensemble import RandomForestClassifier as RanForCla\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding with the analyses in the sub-problems, let us read in the data. Before a previous problem set, we know that there exists missing data for displacement written as `?`. Therefore, we set the `na_values` as such and drop the rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 9)\n"
     ]
    }
   ],
   "source": [
    "auto = pd.read_csv('Auto.csv', na_values='?')\n",
    "print(auto.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "auto = auto.dropna(axis=0)\n",
    "print(auto.shape) ## after dropping the NA values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the variables `mpg_high`, `orgn1`, and `orgn2` as directed by the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = auto['mpg'].median()\n",
    "auto['mpg_high'] = 0\n",
    "auto.loc[auto['mpg'] >= med, 'mpg_high'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto['orgn1'] = 0\n",
    "auto['orgn2'] = 0\n",
    "auto.loc[auto['origin'] == 1, 'orgn1'] = 1\n",
    "auto.loc[auto['origin'] == 2, 'orgn2'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataset would look something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "      <th>mpg_high</th>\n",
       "      <th>orgn1</th>\n",
       "      <th>orgn2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>429.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>4341</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford galaxie 500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>454.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4354</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet impala</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4312</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth fury iii</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
       "5  15.0          8         429.0       198.0    4341          10.0    70   \n",
       "6  14.0          8         454.0       220.0    4354           9.0    70   \n",
       "7  14.0          8         440.0       215.0    4312           8.5    70   \n",
       "\n",
       "   origin                       name  mpg_high  orgn1  orgn2  \n",
       "0       1  chevrolet chevelle malibu         0      1      0  \n",
       "1       1          buick skylark 320         0      1      0  \n",
       "2       1         plymouth satellite         0      1      0  \n",
       "3       1              amc rebel sst         0      1      0  \n",
       "4       1                ford torino         0      1      0  \n",
       "5       1           ford galaxie 500         0      1      0  \n",
       "6       1           chevrolet impala         0      1      0  \n",
       "7       1          plymouth fury iii         0      1      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code checks whether the two variables `orgn1` and `orgn2` have been successfully created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\n",
      "1    245\n",
      "2     68\n",
      "3     79\n",
      "dtype: int64\n",
      "\n",
      "245 68\n"
     ]
    }
   ],
   "source": [
    "## checking whether orgn1 and orgn2 variables have been created well\n",
    "print(auto.groupby(['origin']).size())\n",
    "print()\n",
    "print(auto.orgn1.sum(), auto.orgn2.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us set the y- and x-variables (i.e. the dependent variable and the regressors) to be used in the sub-problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_auto = auto['mpg_high']\n",
    "X_columns = ['cylinders', 'displacement', 'horsepower', 'weight', \n",
    "             'acceleration', 'year', 'orgn1', 'orgn2']\n",
    "X_auto = auto[X_columns]\n",
    "\n",
    "X_auto_vals = X_auto.values\n",
    "y_auto_vals = y_auto.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2-(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part, I use the (revised) function `cv_kf_mlogit` that I implemented from a previous problem set. It is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_kf_mlogit(Xvals, yvals, k=4, rtn_vectors=True, random=25):\n",
    "    ## creating the splits\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=random)\n",
    "    kf.get_n_splits(Xvals)\n",
    "\n",
    "    ## creating the vector of KFolds MSE\n",
    "    MSE_vec_kf = np.zeros(k)\n",
    "    k_ind = int(0)\n",
    "    \n",
    "    for train_idx, test_idx in kf.split(Xvals):\n",
    "        ## splitting training and test sets\n",
    "        X_tr_kf, X_test_kf = Xvals[train_idx], Xvals[test_idx]\n",
    "        y_tr_kf, y_test_kf = yvals[train_idx], yvals[test_idx]\n",
    "\n",
    "        ## making the prediction\n",
    "        mlogit_kf = LR(random_state=random, solver='lbfgs',\n",
    "                       multi_class='multinomial').fit(X_tr_kf, y_tr_kf)\n",
    "        y_pred_kf = mlogit_kf.predict(X_test_kf)\n",
    "\n",
    "        ## indicator function for categorical variables\n",
    "        MSE_indicator_kf = (y_pred_kf != y_test_kf).mean()\n",
    "\n",
    "        ## MSE vector for the specific k-fold\n",
    "        MSE_vec_kf[k_ind] = MSE_indicator_kf\n",
    "        print('Fold #{}:'.format(k_ind+1), 'MSE is {}'.format(MSE_indicator_kf))\n",
    "\n",
    "        ## creating the vectors of actual and test yvals\n",
    "        if k_ind == 0:\n",
    "            y_act, y_pred = y_test_kf, y_pred_kf\n",
    "\n",
    "        else:\n",
    "            y_act = np.hstack((y_act, y_test_kf))\n",
    "            y_pred = np.hstack((y_pred, y_pred_kf))\n",
    "\n",
    "        k_ind += 1\n",
    "\n",
    "    cv_kf = MSE_vec_kf.mean()\n",
    "    print('-------------------------------')\n",
    "    print('CV_KF is {}'.format(cv_kf))\n",
    "\n",
    "    if rtn_vectors:\n",
    "        return cv_kf, y_act, y_pred\n",
    "\n",
    "    else:\n",
    "        return cv_kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the said function, the MSE of the K-folds (with $k=4$) crossvalidation can be found as approximately $0.0969$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1: MSE is 0.14285714285714285\n",
      "Fold #2: MSE is 0.09183673469387756\n",
      "Fold #3: MSE is 0.07142857142857142\n",
      "Fold #4: MSE is 0.08163265306122448\n",
      "-------------------------------\n",
      "CV_KF is 0.09693877551020408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "cv_kf, y_act, y_pred = \\\n",
    "    cv_kf_mlogit(X_auto_vals, y_auto_vals, k=4,\n",
    "                 rtn_vectors=True, random=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the error rates (that is , $1-\\text{precision}$) for each group (i.e. groups `mpg_high=0` and `mpg_high=1`) are as follows. For the low-mpg group (i.e. `mpg_high=1`), the error rate is approximately $0.08$ ($=1-0.92$). On the other hand, for the high-mpg group (i.e. `mpg_high=0`), the error rate is approximately $0.11$ ($=1-0.89$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       196\n",
      "           1       0.89      0.92      0.90       196\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       392\n",
      "   macro avg       0.90      0.90      0.90       392\n",
      "weighted avg       0.90      0.90      0.90       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_act, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2-(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, because the random forest classifier also relies on randomness, let us set `random_state=25`. Using the below chunks of code, let us conduct hyperparameter tuning for random forest classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_gen = RanForCla(random_state=25)\n",
    "\n",
    "param_dist3 = {\n",
    "    'n_estimators': [10, 200],\n",
    "    'max_depth': [3, 8],\n",
    "    'min_samples_split': sp_randint(2, 20),\n",
    "    'min_samples_leaf': sp_randint(2, 20),\n",
    "    'max_features': sp_randint(1, 8)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search3 = \\\n",
    "    RandomizedSearchCV(rfc_gen, param_distributions=param_dist3,\n",
    "                       n_iter=100, n_jobs=-1, cv=4, random_state=25,\n",
    "                       scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandBestEstimator3= RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=8, max_features=3, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=15, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=25, verbose=0, warm_start=False)\n",
      "RandBestParams3= {'max_depth': 8, 'max_features': 3, 'min_samples_leaf': 15, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "RandBestScore3= 0.08928571428571429\n"
     ]
    }
   ],
   "source": [
    "random_search3.fit(X_auto_vals, y_auto_vals)\n",
    "print('RandBestEstimator3=', random_search3.best_estimator_)\n",
    "print('RandBestParams3=', random_search3.best_params_)\n",
    "print('RandBestScore3=', -random_search3.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can then be seen from above that the optimal tuning parameter values are as follows: `max_depth` of 8, `max_features` of 3, `min_samples_leaf` of 15, `min_samples_split` of 2, and finally `n_estimators` of 10. The MSE of optimal results is found to be approximately $0.0893$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2-(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us tune the hyperparameters for the support vector classifier (`sklearn.svm.SVC`) using the following chunks of code. As the question directs, I have initialized the kernel to be radial basis function (`kernel=rbf`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "\n",
    "param_dist4 = {\n",
    "    'C': sp_uniform(loc=0.2, scale=4.0),\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'shrinking': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search4 = \\\n",
    "   RandomizedSearchCV(svc, param_distributions=param_dist4,\n",
    "                      n_iter=100, n_jobs=-1, cv=4, random_state=25,\n",
    "                      scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandBestEstimator4= SVC(C=1.8094629152568114, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=False,\n",
      "  tol=0.001, verbose=False)\n",
      "RandBestParams4= {'C': 1.8094629152568114, 'gamma': 'scale', 'shrinking': False}\n",
      "RandBestScore4= 0.11479591836734694\n"
     ]
    }
   ],
   "source": [
    "random_search4.fit(X_auto_vals, y_auto_vals)\n",
    "print('RandBestEstimator4=', random_search4.best_estimator_)\n",
    "print('RandBestParams4=', random_search4.best_params_)\n",
    "print('RandBestScore4=', -random_search4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the above result, the optimized values for the parameters `C` (penalty parameter), `gamma` (kernel coefficient), and `shrinking` are as follows: (approximately) $1.8095$, `scale`, and `False` respectively. The MSE of the optimal results is approximately $0.1148$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2-(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above parts 2-(a) to 2-(c), the model in 2-(b) -- that is, random forest classifier with maximum depth of 8, maximum number of features of 3, minimum samples in leaf of 15, minimum samples split of 2, and number of estimators being 10 -- had the lowest value of MSE among the three models. Therefore, I would say the model in 2-(b) is the best predictor of `mpg_high` (based on MSE)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
