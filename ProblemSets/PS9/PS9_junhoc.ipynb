{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MACS30150 PS9\n",
    "### Dr. Richard Evans\n",
    "### Submitted by Junho Choi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1-(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the scatterplot and determining which model is the best, let us read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drink = pd.read_csv('strongdrink.txt')\n",
    "cultivar_uniques = list(drink.cultivar.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code chunk will produce the scatterplot we are required to show, with alcohol (or `alco` variable) on the x-axis and color intensity (or `color_int` variable) on the y-axis. The data is divided into three subsets depending on the value of `cultivar`, which has three unique values to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['r', 'g', 'b']\n",
    "for i, val in enumerate(cultivar_uniques):\n",
    "    subset = drink.loc[drink['cultivar']==val, :]\n",
    "    subset_x = subset['alco']\n",
    "    subset_y = subset['color_int']\n",
    "    \n",
    "    plt.scatter(x=subset_x, y=subset_y,\n",
    "                color=colors[i], label=\"cultivar={}\".format(val))\n",
    "\n",
    "plt.ylabel('Color Intensity')\n",
    "plt.xlabel('Alcohol')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1-(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the regressors (or `xvals` below) and the dependent variable (or `yvals` below) with the following code chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvals_columns = ['alco', 'malic', 'tot_phen', 'color_int']\n",
    "xvals = drink[xvals_columns].values\n",
    "yvals = drink['cultivar'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the logistic regression function from Scikit-Learn also uses a `random_state` parameter, let us initialize it to be $25$ as the question asks. Also, we define the dictionary `param_dist1` to be used for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(random_state=25)\n",
    "\n",
    "param_dist1 = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': sp_uniform(0.1, 10.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code chunk, I have define a function called `opt_model` (for \"optimization of model\") that takes in the aforementioned `xvals`, `yvals`, which model to be used, the dictionary containing information about the range of hyperparameters, `randomness` to be used for setting the `random_state`, and `predict` for determining whether to return the predicted classification as well. I have set `n_iter`, `n_jobs`, and `cv` as $200$, $-1$, and $5$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_model(xvals, yvals, model, search_dict, randomness, predict=False):\n",
    "\n",
    "    random_search = \\\n",
    "        RandomizedSearchCV(model, param_distributions=search_dict,\n",
    "                           n_iter=200, n_jobs=-1, cv=5,\n",
    "                           random_state=randomness,\n",
    "                           scoring='neg_mean_squared_error')\n",
    "    \n",
    "    random_search.fit(xvals, yvals)\n",
    "    return_vars = [random_search.best_params_,\n",
    "                   -random_search.best_score_]\n",
    "    \n",
    "    \n",
    "    if predict == True:\n",
    "        pred_yvals = random_search.fit(xvals, yvals)\n",
    "        return_vars.append(pred_yvals)\n",
    "\n",
    "    return return_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this function, for the logistic regression, the best (hyper)parameters are `C` of approximately $2.6659$ and $l1$ penalty. The MSE of optimal result is shown to be approximately $0.1193$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 2.665871587495725, 'penalty': 'l1'}\n",
      "Best score (MSE) is: 0.11931818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "LR_param, LR_score = opt_model(xvals, yvals, LR, param_dist1, 25)\n",
    "print(\"Best parameters are: {}\".format(LR_param))\n",
    "print(\"Best score (MSE) is: {}\".format(LR_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1-(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the similar for random forest classifier. The random forest classifier function from Scikit-Learn also takes in a `random_state` parameter, so let us set it to be $25$ once again. In addition, let us define `param_dict2` to be used for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfclassifier = RandomForestClassifier(random_state=25)\n",
    "\n",
    "param_dist2 = {\n",
    "    'n_estimators':sp_randint(10, 200),\n",
    "    'max_depth': sp_randint(2, 4),\n",
    "    'min_samples_split': sp_randint(2, 20),\n",
    "    'min_samples_leaf': sp_randint(2, 20),\n",
    "    'max_features': sp_randint(1, 4)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the previously defined `opt_model` function, let us plug in the random forest classifier and the above dictionary into this function. The best (hyper)parameters are found to be `max_depth` of 3, `max_features` of 1, `min_samples_leaf` of 13, `min_samples_split` of 18, and finally `n_estimators` of 176. The optimal MSE value is found to be approximately $0.1307$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'max_depth': 3, 'max_features': 1, 'min_samples_leaf': 13, 'min_samples_split': 18, 'n_estimators': 176}\n",
      "Best score (MSE) is: 0.13068181818181818\n"
     ]
    }
   ],
   "source": [
    "rfc_param, rfc_score = opt_model(xvals, yvals, rfclassifier, param_dist2, 25)\n",
    "print(\"Best parameters are: {}\".format(rfc_param))\n",
    "print(\"Best score (MSE) is: {}\".format(rfc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1-(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let us do the similar for the support vector machine classifier; note that the SVM classifier function does not take a `random_state` parameter. We set the kernel to be radial basis function. In addition, let us set up the dictionray `param_dist3` for hyperparameter tuning once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='rbf')\n",
    "\n",
    "param_dist3 = {\n",
    "    'C': sp_uniform(loc=0.1, scale=10.0),\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'shrinking': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the previously defined `opt_model` function, let us plug in the SVM classifier and the above dictionary into this function. The best (hyper)parameters are found to be `C` of approximately $3.3605$, `gamma` of `scale`, and `shrinking` of `True`. The optimal MSE value is found to be approximately $0.1477$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 3.3605112613782553, 'gamma': 'scale', 'shrinking': True}\n",
      "Best score (MSE) is: 0.14772727272727273\n"
     ]
    }
   ],
   "source": [
    "svc_param, svc_score = opt_model(xvals, yvals, svclassifier, param_dist3, 25)\n",
    "print(\"Best parameters are: {}\".format(svc_param))\n",
    "print(\"Best score (MSE) is: {}\".format(svc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1-(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let us do the similar for the multilayer perceptron (MLP) classifier; MLP classifier function provided by Scikit-Learn takes in a `random_state` parameter, so let us set it to be $25$. In addition, let us set up the dictionray `param_dist4` for hyperparameter tuning once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilayerper = MLPClassifier(random_state=25)\n",
    "\n",
    "param_dist4 = {\n",
    "    'hidden_layer_sizes': sp_randint(1, 100),\n",
    "    'activation': ['logistic', 'relu'],\n",
    "    'alpha': sp_uniform(0.1, 10.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, using the previously defined `opt_model` function, let us plug in the MLP classifier and the above dictionary into this function. The best (hyper)parameters are found to be `activation` of `relu`, `alpha` of approximately `2.1589`, and `hidden_layer_sizes` of 68. The optimal MSE value is found to be approximately $0.1932$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'activation': 'relu', 'alpha': 2.158912119744818, 'hidden_layer_sizes': 68}\n",
      "Best score (MSE) is: 0.19318181818181818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp_param, mlp_score = opt_model(xvals, yvals, multilayerper, param_dist4, 25)\n",
    "print(\"Best parameters are: {}\".format(mlp_param))\n",
    "print(\"Best score (MSE) is: {}\".format(mlp_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1-(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I define the function `model_comparisons` below to automatize the processes above and find the best model (in terms of minimized MSE). This function will return the best model, best parameters for the model, and the optimized MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_comparisons(list_of_models, list_of_dictionaries,\n",
    "                      xvals, yvals, randomness=25):\n",
    "    \n",
    "    contender = 0\n",
    "    contender_mse = float('inf')\n",
    "    contender_param = 0\n",
    "    for i, model in enumerate(list_of_models):\n",
    "        dict_to_use = list_of_dictionaries[i]\n",
    "        param, score = opt_model(xvals, yvals, model,\n",
    "                                 dict_to_use, randomness)\n",
    "        if contender_mse > score:\n",
    "            contender = model\n",
    "            contender_mse = score\n",
    "            contender_param = param\n",
    "    \n",
    "    return contender, contender_param, contender_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of models and list of dictionaries to be used in the function are defined as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = [LR, rfclassifier, svclassifier, multilayerper]\n",
    "list_of_dictionaries = [param_dist1, param_dist2, param_dist3, param_dist4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the comparison (or \"horse race\") of models, it is shown that the (multinomial) __logistic regression__ is the best (in terms of minimized MSE) given the hyperparameters being `C` of approximately $2.6659$ and $l1$ penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "bestmodel, bestparam, bestmse = \\\n",
    "    model_comparisons(list_of_models, list_of_dictionaries,\n",
    "                      xvals, yvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=25, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "{'C': 2.665871587495725, 'penalty': 'l1'}\n",
      "0.11931818181818182\n"
     ]
    }
   ],
   "source": [
    "print(bestmodel)\n",
    "print(bestparam)\n",
    "print(bestmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
